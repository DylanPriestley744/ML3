# ============================================================
# EfficientNet-B0 (ImageNet 预训练) + K 折交叉验证 + 概率集成
# 中途打印 batch 进度，方便看训练跑到哪里了
# 标签:
# 0: Angry, 1: Fear, 2: Happy, 3: Sad, 4: Surprise, 5: Neutral
# 目录结构:
#   data_root/train/Angry/*.jpg
#   data_root/train/Fear/*.jpg
#   ...
#   data_root/test/*.jpg
# ============================================================

import os
import glob
import random
import numpy as np
import pandas as pd

from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models

from sklearn.model_selection import StratifiedKFold

# ------------------ 配置区 ------------------
CONFIG = {
    # ⚠️ 请确认这个路径和你 Kaggle 数据一致
    "data_root": "/kaggle/input/mltask3/fer_data/fer_data",

    "n_folds": 5,                # 想先调试快一点可以改成 3
    "batch_size": 128,
    "num_epochs": 20,            # 上限 20 轮，配合 early stopping
    "lr": 3e-4,
    "num_workers": 2,
    "seed": 42,

    "use_class_weights": True,   # 类别不平衡时有用
    "early_stopping_patience": 4,# 验证集 4 轮不提升就停

    "strip_test_ext": False,     # 如果比赛要求 ID 不带 .jpg，就改 True
    "log_interval": 50,          # ★ 每隔多少个 batch 打印一次进度
}
# -----------------------------------------------------


def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(CONFIG["seed"])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)
if torch.cuda.is_available():
    print("GPU:", torch.cuda.get_device_name(0))


# ============================================================
# 1. 加载训练集：所有图片路径 + 标签
# ============================================================
DATA_ROOT = CONFIG["data_root"]
TRAIN_DIR = os.path.join(DATA_ROOT, "train")
TEST_DIR = os.path.join(DATA_ROOT, "test")

print("TRAIN_DIR:", TRAIN_DIR)
print("TEST_DIR :", TEST_DIR)
print("Train class folders:", os.listdir(TRAIN_DIR))

# 文件夹名 -> 标签 id
kaggle_label_map = {
    "Angry": 0,
    "Fear": 1,
    "Happy": 2,
    "Sad": 3,
    "Surprise": 4,
    "Neutral": 5,
}
class_names = sorted(kaggle_label_map.keys())
print("Class names (sorted):", class_names)

image_paths = []
labels = []

exts = ("*.jpg", "*.jpeg", "*.png")

for class_name in class_names:
    class_dir = os.path.join(TRAIN_DIR, class_name)
    files = []
    for ext in exts:
        files.extend(glob.glob(os.path.join(class_dir, ext)))
    files = sorted(files)
    print(f"{class_name}: {len(files)} images")
    image_paths.extend(files)
    labels.extend([kaggle_label_map[class_name]] * len(files))

image_paths = np.array(image_paths)
labels = np.array(labels)
num_classes = len(kaggle_label_map)

print("Total train images:", len(image_paths))


# ============================================================
# 2. 类别权重（防止类别不均衡影响）
# ============================================================
if CONFIG["use_class_weights"]:
    label_counts = np.bincount(labels, minlength=num_classes)
    print("Label counts:", label_counts)
    inv_freq = 1.0 / label_counts
    class_weights = inv_freq / inv_freq.mean()
    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)
    print("Class weights:", class_weights)
else:
    class_weights = None


# ============================================================
# 3. Dataset & Transform（EfficientNet 标准输入）
# ============================================================
# EfficientNet / ImageNet 归一化
imagenet_mean = [0.485, 0.456, 0.406]
imagenet_std  = [0.229, 0.224, 0.225]

train_transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),        # 48x48 灰度 -> 3 通道
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.25, contrast=0.25),
    transforms.ToTensor(),
    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),
])

val_test_transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),
])


class FERDataset(Dataset):
    def __init__(self, paths, labels, transform):
        self.paths = list(paths)
        self.labels = list(labels)
        self.transform = transform

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, idx):
        path = self.paths[idx]
        img = Image.open(path).convert("L")
        if self.transform is not None:
            img = self.transform(img)
        label = self.labels[idx]
        return img, label


class TestDataset(Dataset):
    def __init__(self, img_dir, transform=None):
        paths = []
        for ext in exts:
            paths.extend(glob.glob(os.path.join(img_dir, ext)))
        self.paths = sorted(paths)
        self.ids = [os.path.basename(p) for p in self.paths]
        self.transform = transform

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, idx):
        path = self.paths[idx]
        img = Image.open(path).convert("L")
        if self.transform is not None:
            img = self.transform(img)
        return img, self.ids[idx]


test_dataset = TestDataset(TEST_DIR, transform=val_test_transform)
test_loader = DataLoader(
    test_dataset,
    batch_size=256,
    shuffle=False,
    num_workers=CONFIG["num_workers"],
    pin_memory=True,
)
print("Num test images:", len(test_dataset))


# ============================================================
# 4. 定义 EfficientNet-B0 模型
# ============================================================
def create_efficientnet_b0(num_classes: int):
    # 兼容 torchvision 新旧写法
    try:
        from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights
        backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)
    except Exception:
        backbone = models.efficientnet_b0(pretrained=True)

    in_features = backbone.classifier[1].in_features
    backbone.classifier[1] = nn.Linear(in_features, num_classes)
    return backbone


def get_criterion():
    # 有的 torch 版本支持 label_smoothing，有的没有，所以 try 一下
    try:
        criterion = nn.CrossEntropyLoss(
            weight=class_weights,
            label_smoothing=0.05,
        )
    except TypeError:
        criterion = nn.CrossEntropyLoss(
            weight=class_weights,
        )
    return criterion


# ★★★ 带中途打印的 train_one_epoch ★★★
def train_one_epoch(model, loader, optimizer, criterion, device,
                    epoch, fold, log_interval=50, num_epochs=20):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    num_batches = len(loader)

    for step, (images, targets) in enumerate(loader, 1):
        images = images.to(device, non_blocking=True)
        targets = targets.to(device, non_blocking=True)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        _, preds = torch.max(outputs, 1)
        correct += (preds == targets).sum().item()
        total += targets.size(0)

        # ★ 中途打印：每 log_interval 个 batch 打一次
        if (step % log_interval == 0) or (step == num_batches):
            print(
                f"[Train] Fold {fold} | Epoch [{epoch}/{num_epochs}] "
                f"Step [{step}/{num_batches}] "
                f"Loss: {loss.item():.4f}"
            )

    return running_loss / total, correct / total


def evaluate(model, loader, criterion, device, epoch=None, fold=None):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, targets in loader:
            images = images.to(device, non_blocking=True)
            targets = targets.to(device, non_blocking=True)

            outputs = model(images)
            loss = criterion(outputs, targets)

            running_loss += loss.item() * images.size(0)
            _, preds = torch.max(outputs, 1)
            correct += (preds == targets).sum().item()
            total += targets.size(0)

    return running_loss / total, correct / total


# ============================================================
# 5. K 折交叉验证 + 对 test 做概率平均
# ============================================================
n_folds = CONFIG["n_folds"]
skf = StratifiedKFold(
    n_splits=n_folds,
    shuffle=True,
    random_state=CONFIG["seed"],
)

num_test = len(test_dataset)
all_test_probs = np.zeros((num_test, num_classes), dtype=np.float32)

for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels), start=1):
    print(f"\n========== Fold {fold}/{n_folds} ==========")

    train_paths = image_paths[train_idx]
    train_labels = labels[train_idx]
    val_paths = image_paths[val_idx]
    val_labels = labels[val_idx]

    train_ds = FERDataset(train_paths, train_labels, train_transform)
    val_ds = FERDataset(val_paths, val_labels, val_test_transform)

    train_loader = DataLoader(
        train_ds,
        batch_size=CONFIG["batch_size"],
        shuffle=True,
        num_workers=CONFIG["num_workers"],
        pin_memory=True,
    )
    val_loader = DataLoader(
        val_ds,
        batch_size=CONFIG["batch_size"],
        shuffle=False,
        num_workers=CONFIG["num_workers"],
        pin_memory=True,
    )

    model = create_efficientnet_b0(num_classes).to(device)
    criterion = get_criterion()
    optimizer = optim.AdamW(
        model.parameters(),
        lr=CONFIG["lr"],
        weight_decay=1e-4,
    )
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="min", factor=0.5, patience=2, verbose=True
    )

    best_val_loss = float("inf")
    best_model_path = f"best_efficientnet_fold{fold}.pth"
    patience = CONFIG["early_stopping_patience"]
    no_improve = 0

    for epoch in range(1, CONFIG["num_epochs"] + 1):
        train_loss, train_acc = train_one_epoch(
            model, train_loader, optimizer, criterion, device,
            epoch, fold,
            log_interval=CONFIG["log_interval"],
            num_epochs=CONFIG["num_epochs"],
        )
        val_loss, val_acc = evaluate(model, val_loader, criterion, device, epoch, fold)
        scheduler.step(val_loss)

        print(
            f"[Summary] Fold {fold} | Epoch [{epoch}/{CONFIG['num_epochs']}] "
            f"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | "
            f"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}"
        )

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            no_improve = 0
            torch.save(model.state_dict(), best_model_path)
            print("  => Best model saved.")
        else:
            no_improve += 1
            print(f"  No improvement for {no_improve} epoch(s).")

        if no_improve >= patience:
            print("  Early stopping triggered for this fold.")
            break

    # ---------- 用该折最优模型预测 test ----------
    model.load_state_dict(torch.load(best_model_path, map_location=device))
    model.eval()

    fold_probs = []

    with torch.no_grad():
        for images, _ids in test_loader:
            images = images.to(device, non_blocking=True)
            outputs = model(images)
            probs = torch.softmax(outputs, dim=1).cpu().numpy()
            fold_probs.append(probs)

    fold_probs = np.vstack(fold_probs)
    all_test_probs += fold_probs    # 累加每一折的概率

# 所有折概率平均
all_test_probs /= n_folds
final_preds = all_test_probs.argmax(axis=1)


# ============================================================
# 6. 生成 submission.csv: ID,Emotion
# ============================================================
ids_for_csv = test_dataset.ids
if CONFIG["strip_test_ext"]:
    ids_for_csv = [os.path.splitext(x)[0] for x in ids_for_csv]

submission = pd.DataFrame({
    "ID": ids_for_csv,
    "Emotion": final_preds,
})

print(submission.head())
submission.to_csv("submission.csv", index=False)
print("Saved submission.csv")
